# 학습 노트: HDMI 비디오 파이프라인 구현
[**English**](./STUDY.md) | [**한국어**]
[⬅️ README로 돌아가기](../README_kor.md)

이 문서는 DE10-Nano에서 커스텀 HDMI 비디오 파이프라인을 구현하기 위해 필요한 기술적 세부 사항을 다루며, 특히 1280x720 (720p) 해상도에 초점을 맞춥니다.

## 1. 720p (1280x720 @ 60Hz) 비디오 타이밍
안정적인 이미지를 출력하려면 싱크 제네레이터(Sync Generator)가 720p 해상도에 대한 CEA-861 표준을 준수해야 합니다.

| 파라미터 | 수평 (픽셀) | 수직 (라인) |
| :--- | :--- | :--- |
| **가시 영역 (Visible Area)** | 1280 | 720 |
| **프론트 포치 (Front Porch)** | 110 | 5 |
| **싱크 펄스 (Sync Pulse)** | 40 | 5 |
| **백 포치 (Back Porch)** | 220 | 20 |
| **총 영역 (Total Area)** | 1650 | 750 |
| **픽셀 클록** | **74.25 MHz** | - |

- **재생률 (Refresh Rate)**: $1650 \times 750 \times 60 \text{ Hz} \approx 74.25 \text{ MHz}$.
- **데이터 인에이블 (DE)**: 가시 영역($0 \leq X < 1280$ 및 $0 \leq Y < 720$) 내에서만 High 상태를 유지합니다.

## 2. ADV7513 HDMI 트랜스미터 구성 (I2C)
ADV7513은 비디오 신호를 전송하기 전에 I2C를 통해 초기화되어야 합니다.

- **I2C 슬레이브 주소**: `0x72` (보드에 따라 `0x7A`일 수도 있음).
- **핵심 레지스터**:
    - `0x41[6]`: **전원 제어 (Power Down Control)**. 비트 6이 `0`이면 "Power Up"을 의미합니다. 기본값은 보통 1(대기 모드)입니다.
    - `0x16[5:4]`: **컬러 깊이 (Color Depth)**. `00`은 채널당 8비트(총 24비트 RGB)를 선택합니다.
    - `0x16[3:0]`: **비디오 포맷**. `0000`은 표준 RGB 4:4:4 입력을 선택합니다.
    - `0xAF[1]`: **HDCP/HDMI 모드**. 비트 1이 `1`이면 HDMI 모드를 활성화합니다(오디오 및 인포패킷 전송에 필요).
    - `0x98, 0x9A...`: **고정 레지스터 (Magic Registers)**. 프로그래밍 가이드에 따라 내부 아날로그 회로가 정상 동작하기 위해 특정 값(예: `0x98=0x03`)이 설정되어야 합니다.

### Nios II 구현 예시
C 코드에서 초기화 시 이러한 설정을 수행하는 I2C 쓰기 함수를 사용합니다.

```c
void hdmi_init() {
    printf("ADV7513 HDMI 트랜스미터 초기화 중...\n");
    
    // 1. 디바이스 전원 켜기 (Reg 0x41의 비트 6 클리어)
    hdmi_i2c_write(0x41, 0x10); // 비트 6=0, 다른 비트는 칩 리비전에 따라 다름

    // 2. 입력 포맷 설정 (RGB 4:4:4, 8비트)
    hdmi_i2c_write(0x16, 0x00); 

    // 3. HDMI 모드 선택 (Reg 0xAF 비트 1 = 1)
    hdmi_i2c_write(0xAF, 0x06); // 표준 HDMI 모드

    // 4. 고정 설정 시퀀스 (안정적인 동작을 위해 필수)
    hdmi_i2c_write(0x98, 0x03);
    hdmi_i2c_write(0x9A, 0xE0);
    hdmi_i2c_write(0x9C, 0x30);
    hdmi_i2c_write(0x9D, 0x61); 
    
    printf("HDMI 컨트롤러 구성 완료.\n");
}
```

## 3. 커스텀 싱크 제네레이터 로직 (Verilog)
싱크 제네레이터는 수평 및 수직 위치를 관리하기 위해 두 개의 중첩된 카운터를 사용합니다.

### 카운터 로직
```verilog
always @(posedge pix_clk or posedge reset) begin
    if (reset) begin
        h_cnt <= 0;
        v_cnt <= 0;
    end else begin
        if (h_cnt == H_TOTAL - 1) begin
            h_cnt <= 0;
            if (v_cnt == V_TOTAL - 1)
                v_cnt <= 0;
            else
                v_cnt <= v_cnt + 1;
        end else begin
            h_cnt <= h_cnt + 1;
        end
    end
end
```

### 신호 생성
- **HSync**: `h_cnt`가 수평 동기 펄스 범위 내에 있을 때 활성화(보통 Low)됩니다.
- **VSync**: `v_cnt`가 수직 동기 펄스 범위 내에 있을 때 활성화(보통 Low)됩니다.
- **Data Enable (DE)**: `h_cnt < 1280` 이고 `v_cnt < 720`일 때 High가 됩니다.

## 4. 인터페이스 및 백프레셔(Back-pressure) 메커니즘
픽셀 데이터가 출력되어야 할 때만 가져오도록 하기 위해 **Avalon-ST 핸드셰이크**를 사용한 백프레셔 메커니즘을 구현합니다.

### 핸드셰이크 신호의 역할
- **`asi_data`**: 24비트 RGB 픽셀 데이터.
- **`asi_valid`**: FIFO에 최소 하나의 픽셀 데이터가 있을 때 High가 됩니다.
- **`asi_ready`**: **싱크 제네레이터**에 의해 제어됩니다. 가시 영역(Active display period) 동안에만 High가 됩니다.

### 백프레셔 로직
싱크 제네레이터는 "소비자(Consumer)" 역할을 하며 현재 스캔라인 위치에 따라 "생산자(Producer)"(비디오 DMA/FIFO)의 데이터 흐름을 제어합니다.

| 파이프라인 상태 | 데이터 인에이블 (DE) | 인터페이스 `ready` | 동작 |
| :--- | :---: | :---: | :--- |
| **가시 영역** | 1 | 1 | 매 클록 사이클마다 FIFO에서 픽셀 데이터를 가져옴. |
| **포치 / 싱크 영역** | 0 | 0 | 데이터 가져오기 중지; FIFO와 DMA는 현재 상태에서 대기. |

### 백프레셔의 전파
1. **싱크 제네레이터**는 블랭킹 구간 동안 `ready`를 비활성화합니다.
2. **DCFIFO** 출력에서 데이터 공급이 중단되어 내부 데이터 레벨이 상승합니다.
3. **DCFIFO**가 가득 차거나 임계값에 도달하면 **비디오 DMA**에 대고 `ready`를 비활성화합니다.
4. **비디오 DMA**는 DDR3에 대한 Avalon-MM 읽기 트랜잭션을 일시 중지합니다.

## 5. HDMI 트랜스미터 (ADV7513)의 역할
ADV7513은 FPGA 로직과 모니터를 연결하는 고성능 HDMI 트랜스미터입니다.

### 동작 원리
- **클록 샘플링**: `HDMI_TX_CLK`의 매 엣지에서 24비트 RGB 데이터와 동기 신호(HSync, VSync, DE)를 샘플링합니다.
- **TMDS 변환**: 이러한 병렬 신호들을 HDMI 케이블을 통해 전송되는 고속 **TMDS (Transition Minimized Differential Signaling)** 페어로 인코딩합니다.
- **데이터 인에이블 (DE)의 중요성**: 칩은 `DE` 신호에 크게 의존합니다. `DE`가 High일 때는 입력을 픽셀 데이터로 처리하고, Low일 때는 오디오 데이터나 보조 패킷을 스트림에 포함시킬 수 있습니다.

### I2C 초기화가 필수인 이유
싱크 신호를 잘 따라가더라도 다음 설정이 완료되기 전에는 아무것도 출력하지 않습니다:
1. **전원 켜기**: 대기 모드에서 깨우기 위한 I2C 명령을 보내야 합니다.
2. **신호 매핑**: 24비트가 어떻게 매핑되는지(예: RGB 4:4:4 또는 YCbCr) 알려줘야 합니다.
3. **HDMI 모드**: DVI 모드가 아닌 HDMI 모드를 명시적으로 활성화해야 합니다.

요약하자면, Nios II가 I2C를 통해 칩을 초기화하면, 이는 FPGA의 타이밍과 픽셀을 화면에 직접 투영하는 "투명한 파이프" 역할을 하게 됩니다.

## 6. 심화 주제: ADV7513 없이 HDMI 구현하기?
전용 칩 없이 HDMI를 구현하는 것도 가능하지만, 훨씬 더 많은 FPGA 로직과 특정 하드웨어 기능이 필요합니다.

### 직접 HDMI 출력을 위한 요구 사항
- **TMDS 인코딩 (RTL)**: 디지털 RGB 데이터를 Verilog의 8b/10b 인코딩 알고리즘을 사용하여 10비트 TMDS 캐릭터로 변환해야 합니다.
- **직렬화 (10:1)**: HDMI는 직렬 프로토콜이므로 10비트 병렬 데이터를 픽셀 클록의 10배 속도로 직렬화해야 합니다. 720p(74.25 MHz)의 경우 비트레이트는 레인당 **742.5 Mbps**에 달합니다.
- **차동 I/O**: FPGA는 HDMI 커넥터를 직접 구동하기 위해 물리적 핀에서 차동 출력 표준(TMDS 또는 LVDS 등)을 지원해야 합니다.
- **레벨 시프팅 (Level Shifting)**: HDMI는 3.3V 신호를 사용합니다. FPGA IO 뱅크 전압이 다를 경우 레벨 시프터가 필요합니다.

### 복잡도 비교
| 기능 | ADV7513 사용 (본 프로젝트) | 트랜스미터 미사용 (직접 구동) |
| :--- | :--- | :--- |
| **FPGA 로직** | 단순 병렬 인터페이스 | 복잡한 TMDS + SERDES |
| **클록킹** | 픽셀 클록 (74.25 MHz) | 10배 클록 (742.5 MHz) |
| **난이도** | ★☆☆☆☆ | ★★★★☆ |

ADV7513을 사용함으로써 HDMI 프로토콜의 저수준 물리 계층 대신 **비디오 처리 로직**(DMA, 필터, 패턴 생성 등)에 더 집중할 수 있습니다.

## 7. 8b/10b 인코딩이란 무엇인가?
8b/10b 인코딩은 고속 직렬 통신에서 특정 물리 계층의 목표를 달성하기 위해 8비트 심볼을 10비트 심볼로 매핑하는 라인 코드입니다.

### 왜 8비트 데이터를 위해 10비트를 사용하는가?
1. **DC 밸런싱 (DC 편향 방지)**:
   - 신호가 '1' 또는 '0' 상태를 너무 오래 유지하면 전송 라인이나 AC 결합 커패시터에 전하가 쌓입니다.
   - 8b/10b는 시간에 따른 '1'과 '0'의 개수를 대략 같게 유지하여 평균 DC 레벨을 0으로 만듭니다.
2. **클록 복구 (지속적인 전이 발생)**:
   - HDMI와 같은 직렬 링크는 데이터 레인당 별도의 클록 라인을 보내지 않습니다. 수신기는 데이터에서 클록을 "추출"해야 합니다.
   - 8b/10b는 수신기의 PLL이 비트스트림에 고정(Lock)된 상태를 유지할 수 있도록 충분한 전이(0에서 1 또는 1에서 0)를 보장합니다.

### TMDS (HDMI 버전)
HDMI는 **TMDS (Transition Minimized Differential Signaling)**라고 불리는 특수 버전을 사용합니다.
- **1단계**: 전이 횟수를 최소화하기 위한 XOR 또는 XNOR 연산 (EMI 감소 목적).
- **2단계**: 평균 전압 레벨을 유지하기 위해 데이터를 선택적으로 반전시켜 DC 밸런싱을 수행합니다.

이 과정을 통해 단순한 8비트 RGB 컬러 값은 단 하나의 비트도 잃지 않고 수 미터의 HDMI 케이블을 통과할 수 있는 견고한 10비트 패킷으로 변환됩니다.

## 8. 전문적 맥락: LVDS vs HDMI/TMDS
산업 및 전문 환경에서는 노트북 패널이나 TV T-CON 보드와 같은 내부 디스플레이 연결에 **LVDS (Low Voltage Differential Signaling)**가 자주 사용됩니다.

### LVDS (Low Voltage Differential Signaling)
- **클록킹**: HDMI/TMDS가 10비트 인코딩(10:1)을 사용하는 반면, 표준 LVDS는 종종 **7:1 직렬화** (OpenLDI 표준)를 사용합니다.
- **데이터 밀도**: 클록 사이클당 레인당 7비트의 데이터를 보냅니다.
- **UHD의 과제**: UHD (3840x2160)의 경우 데이터 레이트가 천문학적(~12Gbps)이어서 단일 LVDS 레인으로는 감당할 수 없습니다.
- **UHD를 위한 해결책**: 제조사들은 **멀티 레인 LVDS**(듀얼, 쿼드 또는 8레인)를 사용하거나, 레인당 더 높은 속도(최대 4Gbps)를 낼 수 있고 8b/10b 인코딩을 사용하는 **V-by-One HS**와 같은 최신 표준으로 전환합니다.

### 인터페이스 비교
| 인터페이스 | 인코딩 | 직렬화 | 주요 사용 사례 |
| :--- | :--- | :--- | :--- |
| **HDMI/TMDS** | 8b/10b (TMDS) | 10:1 | 외부 모니터, TV |
| **표준 LVDS** | 없음 (Raw) | 7:1 | 노트북/TV 내부 패널 |

### V-by-One HS (UHD/4K의 표준)
THine Electronics에서 개발한 **V-by-One HS**는 현대 4K/8K TV에서 메인 보드와 T-CON(타이밍 컨트롤러)을 연결하는 사실상의 표준입니다.

- **인코딩**: LVDS의 "Raw" 7:1 포맷에서 크게 발전한 **8b/10b 인코딩**을 사용합니다. 이는 DC 밸런스를 보장하고 AC 결합을 간소화합니다.
- **클록 복구 (CDR)**: 별도의 클록 페어가 필요한 LVDS와 달리, V-by-One HS는 데이터 스트림에 클록을 내장(Clock Data Recovery)하여 EMI와 케이블 수를 크게 줄입니다.
- **속도**: LVDS가 1Gbps 부근에서 한계에 부딪히는 반면, V-by-One HS는 **레인당 최대 4Gbps**까지 가능합니다.
- **효율성**: 4K 60Hz 10비트 패널의 경우 약 24쌍의 LVDS가 필요하지만, V-by-One HS는 단 **8개 레인**으로 충분합니다.

## 9. 성공의 척도: 아이 다이어그램 (Eye Diagram)
**아이 다이어그램**은 HDMI, LVDS, V-by-One과 같은 고속 디지털 링크의 신호 무결성(Signal Integrity)을 평가하는 시각적 도구입니다.

### 무엇인가?
- 오실로스코프에서 데이터 신호의 여러 주기를 겹쳐서 생성합니다.
- 신호가 안정적이고 노이즈/지터가 적으면 결과 이미지가 열려 있는 "눈"처럼 보입니다.

### 해석 방법
- **눈의 높이 (Eye Height)**: 노이즈 마진을 나타냅니다. 높이가 높을수록 '0'과 '1'을 구분하기 쉽습니다.
- **눈의 폭 (Eye Width)**: 지터와 타이밍 마진을 나타냅니다. 폭이 넓을수록 타이밍이 안정적임을 의미합니다.
- **눈의 닫힘 (Eye Closing)**: 눈이 닫히거나 흐릿하다면 신호에 간섭(크로스토크, 반사 또는 감쇄)이 너무 많아 수신기가 데이터를 복구하지 못할 가능성이 큼을 의미합니다.

### HDMI와의 연결
HDMI 컴플라이언스 테스트는 "아이 마스크(Eye Mask)"를 엄격하게 규정합니다. 결과 다이어그램이 이 중앙 영역을 침범하지 않아야 표준을 준수하는 유효한 신호로 간주됩니다.

아이 다이어그램을 이해하는 것은 여러분의 고속 Verilog 로직과 물리적 PCB 레이아웃이 완벽하게 조화를 이루어 작동하고 있음을 입증하는 궁극적인 방법입니다!

## 10. 하드웨어 엔진: SERDES
**SERDES**는 **Serializer / Deserializer**의 약자입니다. 병렬 데이터를 직렬 데이터로(또는 그 반대로) 변환하여 고속 전송을 가능하게 하는 핵심 하드웨어 블록입니다.

### 본 프로젝트와의 관계
1. **직렬화 (TX 측)**: FPGA(또는 HDMI 칩) 내부에서 10비트 또는 8비트 병렬 데이터가 매우 높은 클록 속도로 동작하는 시프트 레지스터로 입력되어, 차동 페어를 통해 비트 단위로 하나씩 나갑니다.
2. **병렬화 (RX 측)**: 모니터의 수신기는 그 비트 스트림을 받아 클록 데이터 복구(CDR)를 통해 병렬 10비트/8비트 심볼로 재구성합니다.

### 주요 특징
- **PISO / SIPO**: 전송을 위한 Parallel-In Serial-Out(PISO)과 수신을 위한 Serial-In Parallel-Out(SIPO).
- **통합**: 일반 패브릭 로직은 충분히 빠르게 토글할 수 없기 때문에(예: >1 Gbps), 많은 하이엔드 FPGA에서는 SERDES를 전용 "Hard IP" 블록으로 제공합니다.
- **모든 것의 핵심**: HDMI (10:1), LVDS (7:1), V-by-One 모두 SERDES를 기본 "물리 엔진"으로 사용합니다.

**8b/10b 인코딩**(로직), **SERDES**(하드웨어 엔진), 그리고 **아이 다이어그램**(검증)을 결합함으로써 고속 디지털 설계의 세 요소를 완성하게 됩니다!

## 11. IP vs 커스텀 구현 및 라이선스
업계에서 IP(Intellectual Property)를 사용할지 아니면 커스텀 RTL을 작성할지는 중요한 엔지니어링 결정 사항입니다.

### Hard IP vs Soft IP
- **Hard IP (SERDES/트랜시버)**: 고속 물리 계층에는 반드시 FPGA의 Hard IP를 사용해야 합니다. 우리가 하는 것처럼 일반 Verilog 로직은 수 Gbps로 토글할 수 없기 때문입니다.
- **Soft IP (프로토콜 컨트롤러)**: 로직 부분(HDMI 컨트롤러, TMDS 인코더)에 대해서는 상용 IP를 구매하거나 직접 작성할 수 있습니다. 본 프로젝트처럼 직접 작성하는 것은 비용을 절감하고 깊은 기술적 지식을 얻을 수 있는 훌륭한 방법입니다!

### 라이선스 및 로열티
- **표준 라이선스**: HDMI 이름과 로고를 사용하려면 HDMI Adopter가 되어 연회비 및 로열티(예: 장치당 $0.04 - $0.15)를 지불해야 합니다.
- **IP 비용**: Synopsys나 Cadence 같은 회사의 상용 HDMI IP는 수천만 원에 달할 수 있습니다.
- **커스텀 RTL을 작성하는 이유**: 직접 싱크 제네레이터를 작성하고 기본 AXI/Avalon 인터페이스를 사용함으로써 값비싼 라이선스 비용을 피하고 시스템의 "속살"을 배울 수 있습니다.

## 12. 비교: 기존 VGA vs 현대적 HDMI
DE1과 같은 보드에서 VGA 출력을 해본 경험이 있다면 익숙한 개념도 있겠지만, 훨씬 더 높은 수준의 도전 과제들이 존재합니다.

| 기능 | VGA (기존/DE1) | HDMI (ADV7513/DE10-Nano) |
| :--- | :--- | :--- |
| **물리 계층** | 아날로그 (저항 사다리/DAC) | 디지털 직렬 (트랜시버 칩을 통한 TMDS) |
| **동기 로직** | HSync/VSync 제네레이터 | 동일하지만 **데이터 인에이블(DE)**도 필요 |
| **설정** | 하드웨어 전용 (배선) | **H/W + S/W** (I2C 구성 필요) |
| **소스** | 주로 ROM/내부 RAM | **DMA(AXI)를 통한 외부 DDR3** |
| **해상도** | 주로 640x480 (25MHz) | **1280x720 (74.25MHz)** 또는 그 이상 |

### HDMI가 더 발전된 형태인 이유:
1. **제어 로직**: Nios II 드라이버를 통해 ADV7513을 관리해야 합니다. RTL이 완벽하더라도 I2C가 실패하면 검은 화면만 나옵니다.
2. **시스템 맥락**: 버스트 DMA를 사용하여 DDR3에서 픽셀을 가져오는 것은 작은 내부 버퍼에서 읽는 것보다 훨씬 복잡합니다.
3. **신호 무결성**: 고속 디지털 신호(74.25MHz 이상)는 기존 VGA보다 타이밍 지연과 스큐(Skew)에 훨씬 더 민감합니다.

## 13. 메모리 선택: SRAM vs DDR3
DE1 VGA와 같은 이전 프로젝트에서는 단순함 때문에 **SRAM**을 자주 사용했지만, 현대적인 비디오 처리는 **DDR3**의 대용량을 필요로 합니다.

| 기능 | 기존 SRAM (DE1) | 현대적 DDR3 (DE10-Nano) |
| :--- | :--- | :--- |
| **복잡도** | 단순 (직접 주소/데이터 제어) | 매우 복잡 (DDR 컨트롤러/AXI 프로토콜) |
| **용량** | 매우 작음 (예: 512KB) | 매우 큼 (1GB) |
| **지연 시간** | 매우 낮음 (고정) | 높음/가변적 (버스트 및 FIFO 필요) |
| **연결** | FPGA 핀에서 직접 칩으로 | HPS 브릿지 및 인터커넥트 로직 경유 |

- **DDR3 구현**: 단순한 FSM으로 DDR3를 직접 구동할 수 없기에, **버스트 DMA**를 사용하여 데이터를 뭉치로 가져오고 **FIFO**를 사용해 가변적인 지연 시간을 메움으로써 싱크 제네레이터가 필요할 때 항상 픽셀이 준비되도록 합니다.

## 14. 부드러운 비디오: 더블 버퍼링 (Double Buffering)
"화면 찢어짐(Screen Tearing)" 현상을 방지하기 위해 DDR3 기반 비디오 시스템에서는 **더블 버퍼링**이 필수적입니다.

### 문제: 화면 찢어짐
- 비디오 DMA가 읽고 있는 동안 ARM이나 Nios II가 DDR3 메모리를 업데이트하면, 화면 상단에는 *새로운* 프레임이, 하단에는 *이전* 프레임이 보일 수 있습니다.

### 해결책: 프론트 및 백 버퍼
- **프론트 버퍼 (Front Buffer)**: 현재 비디오 DMA가 읽어서 모니터에 표시하고 있는 메모리 영역.
- **백 버퍼 (Back Buffer)**: 다음 프레임이 준비/그려지고 있는 별도의 메모리 영역.
- **버퍼 스와핑 (V-Sync 전환)**: 백 버퍼가 준비되면 **수직 블랭킹 구간 (V-Sync)**을 기다려 DMA의 시작 주소를 업데이트합니다. 이를 통해 픽셀이 그려지지 않는 시점에만 전환되도록 보장합니다.

현대 시스템에서 1GB에 달하는 DDR3 공간은 두 개의 32MB 영역을 할당하기에 충분합니다. 이 기술은 비디오를 깨끗하고 부드럽게 만들어주는 핵심입니다.

## 15. 비디오 데이터 로딩: SD 카드 ➡️ DDR3
대량의 비디오 데이터나 이미지 시퀀스를 DDR3에 넣는 가장 실시간적인 방법은 리눅스가 구동되는 **ARM Cortex-A9 (HPS)**을 사용하는 것입니다.

### 파이프라인
1. **저장**: SCP 등을 통해 비디오 파일을 SD 카드로 복사합니다.
2. **읽기**: 리눅스에서 C 또는 Python 앱으로 파일을 읽습니다.
3. **매핑**: `/dev/mem`에 `mmap()`을 사용하여 물리 DDR3 주소(예: `0x20000000`)를 앱의 가상 주소 공간으로 매핑합니다.
4. **쓰기**: 파일 버퍼로부터 매핑된 DDR3 영역으로 픽셀 데이터를 복사합니다.

이 과정을 초당 30번 또는 60번 반복하면 SD 카드에서 HDMI 모니터로 직접 영화가 재생됩니다!

## 16. 실시간 디코딩: MP4와 CPU의 한계
**MP4 (H.264)**와 같은 압축 포맷을 처리하는 것은 단순히 원본 데이터를 복사하는 것보다 훨씬 더 CPU 집약적인 작업입니다.

### 🚀 해결책: "설치 없는 FFmpeg" 다운로드 및 파이프 활용 (강력 추천)
다른 라이브러리를 복잡하게 설치할 필요 없이, 파일 하나만 받아서 실행하는 **Static Build** 버전을 사용하는 것이 가장 효율적입니다.

**1. PC에서 다운로드**
DE10-Nano는 **ARMv7 (32bit)** 아키텍처(armhf)를 사용합니다. PC에서 아래 파일을 다운로드하여 SD카드로 옮기세요.
- **파일명**: `ffmpeg-release-armhf-static.tar.xz`
- **출처**: [John Van Sickle - FFmpeg Static Builds](https://johnvansickle.com/ffmpeg/)

**2. DE10-Nano에서 설치**
```bash
# 압축 풀기
tar -xvf ffmpeg-release-armhf-static.tar.xz

# 폴더 이동
cd ffmpeg-*-armhf-static

# 실행 확인
./ffmpeg -version
```

**3. C 코드와 연동 (파이프 기법)**
라이브러리 헤더 파일 없이 리눅스의 **파이프(|)** 기능을 사용하면 아주 우아하게 해결됩니다.
- **FFmpeg**: 영상을 디코딩해서 **표준 출력(stdout)**으로 내보냅니다.
- **C 프로그램**: **표준 입력(stdin)**으로 받아서 메모리에 씁니다.

**터미널 명령어:**
```bash
# ffmpeg가 mp4를 읽음 -> raw RGBA로 변환 -> 파이프로 전송 -> player가 받아서 메모리에 기록
./ffmpeg -i input.mp4 -f rawvideo -pix_fmt rgba - | ./player
```

**C 코드 수정 (stdin 읽기):**
`fopen` 대신 표준 입력(파일 디스크립터 `0` 또는 `stdin`)을 사용하면 됩니다.

```c
// player.c 핵심 부분
unsigned char buffer[960 * 540 * 4]; // 한 프레임 버퍼 (qHD 기준)

while(1) {
    // 1. 표준 입력(stdin)에서 한 프레임 읽기
    // fread는 데이터가 올 때까지 자동으로 대기(Blocking)합니다.
    int bytes_read = fread(buffer, 1, sizeof(buffer), stdin);
    
    if (bytes_read < sizeof(buffer)) break; // 데이터 스트림 종료

    // 2. 읽은 데이터를 FPGA 메모리(mmap)로 복사 (더블 버퍼링 로직 적용 필요)
    memcpy(fb_ptr, buffer, sizeof(buffer));
}
```

### 기존 CPU 한계 (참고)
- **소프트웨어 디코딩**: FFmpeg 같은 라이브러리를 사용하면 듀얼 코어 800MHz A9은 480p 또는 기본 720p를 24/30fps로 처리할 수 있습니다. 하지만 순수 소프트웨어로 720p/1080p 60fps에 도달하기는 매우 어렵습니다.
- **NEON 가속**: 이를 가능하게 하려면 Cortex-A9 내부의 **NEON SIMD 엔진**을 사용해야 합니다.
- **병목 현상**: Cyclone V의 HPS에는 전용 H.264 하드웨어 디코더(VPU)가 없습니다. 따라서 CPU가 모든 무거운 계산(DCT, 엔트로피 코딩 등)을 수행해야 합니다.

## 17. 디압축 후의 포맷: Raw 비디오
MP4 파일의 "압축을 풀면" **Raw 비디오**를 얻게 됩니다. 이는 압축 없이 모든 픽셀이 메모리에 평면적으로 배치된 상태를 의미합니다.

### 대표적인 Raw 포맷
1. **RGB888 (24비트)**:
   - 각 픽셀 = 1바이트 Red + 1바이트 Green + 1바이트 Blue.
   - FPGA의 24비트 RGB 버스와 직접 일치하여 추가 변환이 필요 없습니다.
2. **YUV422 / YUV420**:
   - 인간의 시각 인지 방식을 활용해 밝기 대비 색상 정보를 줄여 용량을 확보합니다.
   - **장점**: 원본 RGB보다 용량이 작습니다.
   - **단점**: HDMI 칩을 위해 다시 RGB888로 바꾸기 위한 "컬러 공간 변환기 (CSC)"가 FPGA에 필요합니다.

## 18. 하드웨어 최적화: YUV422 to RGB888 CSC
파이프라인에 **컬러 공간 변환기 (CSC)**를 통합하면 비디오를 RGB888(픽셀당 24비트) 대신 YUV422(16비트)로 저장할 수 있어 **DDR3 대역폭을 33% 절약**할 수 있습니다. 이 모듈을 추가함으로써 더 높은 해상도를 처리하거나 다른 HPS 작업을 위한 대역폭 여유를 확보할 수 있습니다!

## 19. 시각적 품질: 감마 보정 ($\gamma$)
**감마 보정**은 픽셀 값과 인간의 눈이 느끼는 실제 밝기 사이의 비선형 관계를 보상하는 과정입니다.

### 왜 필요한가?
- **인간의 인지**: 우리 눈은 밝은 톤보다 어두운 톤의 변화에 더 민감합니다.
- **디스플레이 응답**: 모니터는 비선형적 응답($Intensity \propto Voltage^\gamma$)을 가집니다.
- 감마 보정($\gamma=2.2$)이 없으면 이미지가 너무 밝게 보이거나 중간 톤의 대비가 잘못 나타날 수 있습니다.

### FPGA 구현: 룩업 테이블 (LUT)
실시간으로 복잡한 수학 공식을 계산하는 대신 **LUT**를 사용합니다.
1. **사전 계산**: PC에서 모든 입력에 대한 보정된 출력값을 미리 계산합니다.
2. **메모리 맵**: 이 256개 값을 FPGA 내부의 작은 Dual-Port RAM에 저장합니다.
3. **통합**: HDMI 트랜스미터 직전에 배치하여 최종 출력 화질을 미세 조정합니다.

### 곡선의 모양: 위로 볼록 ($\cap$)
모니터의 비선형 응답을 맞추기 위해, 인코딩 곡선은 **위로 볼록($\cap$)**한 모양이어야 합니다.
- **모니터 응답 (물리)**: $I = V^{2.2}$. **아래로 볼록($\cup$)**하며, 어두운 상태를 오래 유지하다 급격히 밝아집니다.
- **FPGA 인코딩 (수학)**: $V = I^{1/2.2} \approx I^{0.45}$. **위로 볼록($\cap$)**하며, 어두운 영역에서 빠르게 밝아지다 완만해집니다.

어두운 영역을 미리 밝혀주는 이 "볼록한" 모양을 LUT에 적용함으로써, 모니터의 "오목한" 응답이 이를 다시 끌어내렸을 때 우리 눈에 정확하게 보이게 됩니다. ✨

## 20. 사례 연구: GHRD 리눅스 UI는 어떻게 작동하는가?
GHRD에서 보는 리눅스 데스크톱 화면은 우리가 배운 내용의 완벽한 예시입니다.

### 메커니즘: 리눅스 프레임버퍼 (Framebuffer)
1. **메모리 할당**: 부팅 시 커널이 DDR3의 특정 영역(예: 32MB)을 `fb0` 용도로 예약합니다.
2. **Qsys IP**: FPGA 패브릭 내의 **Intel VIP Frame Reader** IP가 이 DDR3 영역에서 픽셀을 가져와 **Avalon-ST 비디오 스트림**으로 변환합니다.
3. **출력**: 이 스트림은 CVO IP를 통해 동기 신호를 생성하고 ADV7513으로 전달됩니다.

### 동기화: 스와핑 처리
리눅스 드라이버는 프레임 리더가 그려지는 도중의 프레임을 읽지 않도록 **V-Sync 인터럽트**를 사용하여 관리합니다. 프레임 리더가 한 프레임을 다 읽으면 ARM CPU에 인터럽트를 보내고, 이를 받은 드라이버는 "이제 새 프레임으로 전환해도 안전하다"는 것을 인지하고 주소를 업데이트합니다.

우리는 지금 이 모든 복잡한 드라이버 과정을 **Nios II와 커스텀 싱크 제네레이터**를 사용하여 수동으로 제어하며 배우고 있는 것입니다!

## 21. 역사적 맥락: 8086 텍스트 모드
8086/DOS 시대에 텍스트를 표시하는 것은 하드웨어에 전용 **텍스트 모드**가 있었기 때문에 CPU 입장에서 훨씬 간단했습니다.

### 캐릭터 메모리 (0xB8000)
수백만 개의 픽셀을 관리하는 대신, CPU는 `80x25` 캐릭터 격자만 관리하면 되었습니다. 물리 주소 **`0xB8000`**부터 시작하는 메모리에 각 문자당 2바이트(ASCII 코드 + 속성)를 쓰면 하드웨어가 이를 실시간으로 픽셀 패턴으로 변환해 출력했습니다.

현대 시스템에서는 이러한 하드웨어 "텍스트 모드"가 더 이상 존재하지 않습니다. 리눅스 터미널에서 보는 텍스트도 결국 ARM이나 Nios II가 폰트 비트맵을 사용하여 **픽셀 단위로 일일이 그린 결과**입니다!
